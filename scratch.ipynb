{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch - for testing python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "c = np.vstack((a, b))  # Stacks vertically\n",
    "d = np.hstack((a, b))  # Stacks horizontally\n",
    "\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "c = np.concatenate((a, b), axis=0)\n",
    "print(c)\n",
    "\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6]])\n",
    "\n",
    "c = np.concatenate((a, b), axis=0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "c = np.append(a, b)\n",
    "print(c)\n",
    "\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6]])\n",
    "\n",
    "c = np.append(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "stats = np.array([ \n",
    "    [20, 70, 30, 80, 50, 30], # should be dropped because it is the same or lower as the next row\n",
    "    [20, 70, 30, 80, 50, 30], # kept because the in the first value is higher than any other row\n",
    "    [25, 60, 20, 60, 40, 20], # kept because the in the first value of 25 is higher than any other row\n",
    "    [20, 40, 30, 80, 50, 40], # kept because the 3rd value of 30 is higher than any other row\n",
    "])\n",
    "\n",
    "# 2-dimensional weights array with multiple sets of weights\n",
    "weights = np.array([\n",
    "    [3, -4, 2, -2, -1, -1],\n",
    "    [-2, 1, 2, -2, -1, -1],\n",
    "    [3, -3, 3, -2, -1, -1],\n",
    "    [-2, 1, 2, -2, -1, -1],\n",
    "    # Add more sets of weights as needed, up to 252\n",
    "])\n",
    "\n",
    "# Add the weights to the stats array using broadcasting\n",
    "results = stats + weights\n",
    "\n",
    "# Function to round down to the nearest 5\n",
    "def round_down_to_nearest_5(x):\n",
    "    return x // 5 * 5\n",
    "\n",
    "# Apply the rounding function using numpy vectorization\n",
    "rounded_results = round_down_to_nearest_5(results)\n",
    "\n",
    "# Use numpy's unique function to get unique rows\n",
    "unique_results = np.unique(rounded_results, axis=0)\n",
    "\n",
    "# Print the results\n",
    "print(unique_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20.  70.  30.  80.  50.  30. 280.]\n",
      " [ 20.  70.  30.  80.  50.  30. 280.]\n",
      " [ 20.  40.  30.  80.  50.  40. 260.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_additional_fields(outfits):\n",
    "    # Create an array to hold the additional fields\n",
    "    additional_fields = np.zeros((outfits.shape[0], outfits.shape[1] + 6))\n",
    "    \n",
    "    # Copy the original outfits array\n",
    "    additional_fields[:, :outfits.shape[1]] = outfits\n",
    "    \n",
    "    # Compute the sum of each attribute with the total points, give the stat a weight of 10\n",
    "    for i in range(6):\n",
    "        additional_fields[:, outfits.shape[1] + i] = outfits[:, i] * 10 + outfits[:, 6]\n",
    "    \n",
    "    return additional_fields\n",
    "\n",
    "def find_peak_values(fields):\n",
    "    # Find the maximum values for each field\n",
    "    peak_values = np.max(fields, axis=0)\n",
    "    return peak_values\n",
    "\n",
    "def is_pinnacle(outfit, peak_values, num_original_fields):\n",
    "    # Check if the outfit has at least one field at its peak value\n",
    "    for i in range(num_original_fields, len(outfit)):\n",
    "        if outfit[i] == peak_values[i]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_pinnacle_outfits(outfits):\n",
    "    additional_fields = compute_additional_fields(outfits)\n",
    "    peak_values = find_peak_values(additional_fields)\n",
    "    num_original_fields = outfits.shape[1]\n",
    "    \n",
    "    pinnacle_outfits = []\n",
    "    \n",
    "    for outfit in additional_fields:\n",
    "        if is_pinnacle(outfit, peak_values, num_original_fields):\n",
    "            pinnacle_outfits.append(outfit[:num_original_fields])\n",
    "    \n",
    "    return np.array(pinnacle_outfits)\n",
    "\n",
    "# Example usage\n",
    "outfits = np.array([\n",
    "    [20, 70, 30, 80, 50, 30, 280], \n",
    "    [20, 70, 30, 80, 50, 30, 280], \n",
    "    [25, 60, 20, 60, 40, 20, 225], \n",
    "    [20, 40, 30, 80, 50, 40, 260], \n",
    "    [20, 70, 30, 80, 50, 25, 275], \n",
    "])\n",
    "\n",
    "pinnacle_outfits = find_pinnacle_outfits(outfits)\n",
    "print(pinnacle_outfits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the data type for the structured numpy array\n",
    "dtype = np.dtype([\n",
    "    ('mobility', np.int64),\n",
    "    ('resilience', np.int64),\n",
    "    ('recovery', np.int64),\n",
    "    ('discipline', np.int64),\n",
    "    ('intellect', np.int64),\n",
    "    ('strength', np.int64),\n",
    "    ('helmet', np.int64),\n",
    "    ('gauntlets', np.int64),\n",
    "    ('chest_armor', np.int64),\n",
    "    ('leg_armor', np.int64),\n",
    "    ('class_item', np.int64),\n",
    "    ('num_artifice', np.int64)\n",
    "])\n",
    "\n",
    "# outfit_array = np.empty((0,), dtype=dtype)\n",
    "outfit_array = np.array([(20, 70, 30, 80, 50, 30, 100, 101, 102, 103, 104, 4),\n",
    "                         (25, 30, 20, 70, 50, 70, 100, 101, 107, 106, 104, 2)], dtype=dtype)\n",
    "\n",
    "print(outfit_array['num_artifice'])\n",
    "outfit_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Position1' 'Position2']\n",
      "[[1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the structured data type\n",
    "dt = np.dtype([('Name', np.unicode_, 16), ('Value', np.float64, (1,))])\n",
    "\n",
    "# Create an array with this data type\n",
    "arr = np.array([('Position1', 1.0), ('Position2', 2.0)], dtype=dt)\n",
    "\n",
    "# Access elements by name\n",
    "print(arr['Name'])\n",
    "print(arr['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list\n",
    "data = []\n",
    "\n",
    "# Append data as it becomes available\n",
    "for _ in range(1000000):  # Replace this with your actual loop\n",
    "    row = np.random.rand(30)  # Replace this with your actual data\n",
    "    data.append(row)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "data = np.array(data)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mobility', 'resilience', 'recovery')\n",
      "('mobility', 'resilience', 'discipline')\n",
      "('mobility', 'resilience', 'intellect')\n",
      "('mobility', 'resilience', 'strength')\n",
      "('mobility', 'recovery', 'resilience')\n",
      "('mobility', 'recovery', 'discipline')\n",
      "('mobility', 'recovery', 'intellect')\n",
      "('mobility', 'recovery', 'strength')\n",
      "('mobility', 'discipline', 'resilience')\n",
      "('mobility', 'discipline', 'recovery')\n",
      "('mobility', 'discipline', 'intellect')\n",
      "('mobility', 'discipline', 'strength')\n",
      "('mobility', 'intellect', 'resilience')\n",
      "('mobility', 'intellect', 'recovery')\n",
      "('mobility', 'intellect', 'discipline')\n",
      "('mobility', 'intellect', 'strength')\n",
      "('mobility', 'strength', 'resilience')\n",
      "('mobility', 'strength', 'recovery')\n",
      "('mobility', 'strength', 'discipline')\n",
      "('mobility', 'strength', 'intellect')\n",
      "('resilience', 'mobility', 'recovery')\n",
      "('resilience', 'mobility', 'discipline')\n",
      "('resilience', 'mobility', 'intellect')\n",
      "('resilience', 'mobility', 'strength')\n",
      "('resilience', 'recovery', 'mobility')\n",
      "('resilience', 'recovery', 'discipline')\n",
      "('resilience', 'recovery', 'intellect')\n",
      "('resilience', 'recovery', 'strength')\n",
      "('resilience', 'discipline', 'mobility')\n",
      "('resilience', 'discipline', 'recovery')\n",
      "('resilience', 'discipline', 'intellect')\n",
      "('resilience', 'discipline', 'strength')\n",
      "('resilience', 'intellect', 'mobility')\n",
      "('resilience', 'intellect', 'recovery')\n",
      "('resilience', 'intellect', 'discipline')\n",
      "('resilience', 'intellect', 'strength')\n",
      "('resilience', 'strength', 'mobility')\n",
      "('resilience', 'strength', 'recovery')\n",
      "('resilience', 'strength', 'discipline')\n",
      "('resilience', 'strength', 'intellect')\n",
      "('recovery', 'mobility', 'resilience')\n",
      "('recovery', 'mobility', 'discipline')\n",
      "('recovery', 'mobility', 'intellect')\n",
      "('recovery', 'mobility', 'strength')\n",
      "('recovery', 'resilience', 'mobility')\n",
      "('recovery', 'resilience', 'discipline')\n",
      "('recovery', 'resilience', 'intellect')\n",
      "('recovery', 'resilience', 'strength')\n",
      "('recovery', 'discipline', 'mobility')\n",
      "('recovery', 'discipline', 'resilience')\n",
      "('recovery', 'discipline', 'intellect')\n",
      "('recovery', 'discipline', 'strength')\n",
      "('recovery', 'intellect', 'mobility')\n",
      "('recovery', 'intellect', 'resilience')\n",
      "('recovery', 'intellect', 'discipline')\n",
      "('recovery', 'intellect', 'strength')\n",
      "('recovery', 'strength', 'mobility')\n",
      "('recovery', 'strength', 'resilience')\n",
      "('recovery', 'strength', 'discipline')\n",
      "('recovery', 'strength', 'intellect')\n",
      "('discipline', 'mobility', 'resilience')\n",
      "('discipline', 'mobility', 'recovery')\n",
      "('discipline', 'mobility', 'intellect')\n",
      "('discipline', 'mobility', 'strength')\n",
      "('discipline', 'resilience', 'mobility')\n",
      "('discipline', 'resilience', 'recovery')\n",
      "('discipline', 'resilience', 'intellect')\n",
      "('discipline', 'resilience', 'strength')\n",
      "('discipline', 'recovery', 'mobility')\n",
      "('discipline', 'recovery', 'resilience')\n",
      "('discipline', 'recovery', 'intellect')\n",
      "('discipline', 'recovery', 'strength')\n",
      "('discipline', 'intellect', 'mobility')\n",
      "('discipline', 'intellect', 'resilience')\n",
      "('discipline', 'intellect', 'recovery')\n",
      "('discipline', 'intellect', 'strength')\n",
      "('discipline', 'strength', 'mobility')\n",
      "('discipline', 'strength', 'resilience')\n",
      "('discipline', 'strength', 'recovery')\n",
      "('discipline', 'strength', 'intellect')\n",
      "('intellect', 'mobility', 'resilience')\n",
      "('intellect', 'mobility', 'recovery')\n",
      "('intellect', 'mobility', 'discipline')\n",
      "('intellect', 'mobility', 'strength')\n",
      "('intellect', 'resilience', 'mobility')\n",
      "('intellect', 'resilience', 'recovery')\n",
      "('intellect', 'resilience', 'discipline')\n",
      "('intellect', 'resilience', 'strength')\n",
      "('intellect', 'recovery', 'mobility')\n",
      "('intellect', 'recovery', 'resilience')\n",
      "('intellect', 'recovery', 'discipline')\n",
      "('intellect', 'recovery', 'strength')\n",
      "('intellect', 'discipline', 'mobility')\n",
      "('intellect', 'discipline', 'resilience')\n",
      "('intellect', 'discipline', 'recovery')\n",
      "('intellect', 'discipline', 'strength')\n",
      "('intellect', 'strength', 'mobility')\n",
      "('intellect', 'strength', 'resilience')\n",
      "('intellect', 'strength', 'recovery')\n",
      "('intellect', 'strength', 'discipline')\n",
      "('strength', 'mobility', 'resilience')\n",
      "('strength', 'mobility', 'recovery')\n",
      "('strength', 'mobility', 'discipline')\n",
      "('strength', 'mobility', 'intellect')\n",
      "('strength', 'resilience', 'mobility')\n",
      "('strength', 'resilience', 'recovery')\n",
      "('strength', 'resilience', 'discipline')\n",
      "('strength', 'resilience', 'intellect')\n",
      "('strength', 'recovery', 'mobility')\n",
      "('strength', 'recovery', 'resilience')\n",
      "('strength', 'recovery', 'discipline')\n",
      "('strength', 'recovery', 'intellect')\n",
      "('strength', 'discipline', 'mobility')\n",
      "('strength', 'discipline', 'resilience')\n",
      "('strength', 'discipline', 'recovery')\n",
      "('strength', 'discipline', 'intellect')\n",
      "('strength', 'intellect', 'mobility')\n",
      "('strength', 'intellect', 'resilience')\n",
      "('strength', 'intellect', 'recovery')\n",
      "('strength', 'intellect', 'discipline')\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "items = [\"mobility\", \"resilience\", \"recovery\", \"discipline\", \"intellect\", \"strength\"]\n",
    "\n",
    "# Generate all permutations of length 2\n",
    "permutations = list(itertools.permutations(items, 3))\n",
    "\n",
    "# Print the permutations\n",
    "for p in permutations:\n",
    "    print(p)\n",
    "\n",
    "print(len(permutations))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20  70  30  80  50  30 280]\n",
      " [ 20  70  30  80  50  30 280]\n",
      " [ 25  60  20  60  40  20 225]\n",
      " [ 20  40  30  80  50  40 260]\n",
      " [ 20  70  30  80  50  25 275]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_peak_values(outfits):\n",
    "    # Find the maximum values for each attribute and total points\n",
    "    peak_values = np.max(outfits, axis=0)\n",
    "    return peak_values\n",
    "\n",
    "def is_pinnacle(outfit, peak_values):\n",
    "    # Check if the outfit has at least one attribute at its peak value\n",
    "    # and that no other outfit exceeds it in total points\n",
    "    for i in range(7):  # Check each attribute + total points\n",
    "        if outfit[i] == peak_values[i]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_pinnacle_outfits(outfits):\n",
    "    peak_values = find_peak_values(outfits)\n",
    "    pinnacle_outfits = []\n",
    "\n",
    "    for outfit in outfits:\n",
    "        if is_pinnacle(outfit, peak_values):\n",
    "            pinnacle_outfits.append(outfit)\n",
    "    \n",
    "    return np.array(pinnacle_outfits)\n",
    "\n",
    "# Example usage\n",
    "outfits = np.array([\n",
    "    [20, 70, 30, 80, 50, 30, 280], \n",
    "    [20, 70, 30, 80, 50, 30, 280], \n",
    "    [25, 60, 20, 60, 40, 20, 225], \n",
    "    [20, 40, 30, 80, 50, 40, 260], \n",
    "    [20, 70, 30, 80, 50, 25, 275], \n",
    "])\n",
    "\n",
    "pinnacle_outfits = find_pinnacle_outfits(outfits)\n",
    "print(pinnacle_outfits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original stats array\n",
    "stats = np.array([17, 74, 33, 82, 51, 31])\n",
    "\n",
    "# 2-dimensional weights array\n",
    "weights = np.array([\n",
    "    [3, -4, 2, -2, -1, -1],\n",
    "    [-2, 1, 2, -2, -1, -1],\n",
    "    # Add up to 252 sets of weights\n",
    "])\n",
    "\n",
    "# Add the weights to the stats array using broadcasting\n",
    "results = stats + weights\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15 75 35 80 50 30]\n",
      " [20 70 35 80 50 30]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original stats array\n",
    "stats = np.array([17, 74, 33, 82, 51, 31])\n",
    "\n",
    "# 2-dimensional weights array with multiple sets of weights\n",
    "weights = np.array([\n",
    "    [3, -4, 2, -2, -1, -1],\n",
    "    [-2, 1, 2, -2, -1, -1],\n",
    "    [3, -3, 3, -2, -1, -1],\n",
    "    [-2, 1, 2, -2, -1, -1],\n",
    "    # Add more sets of weights as needed, up to 252\n",
    "])\n",
    "\n",
    "# Add the weights to the stats array using broadcasting\n",
    "results = stats + weights\n",
    "\n",
    "# Function to round down to the nearest 5\n",
    "def round_down_to_nearest_5(x):\n",
    "    return x // 5 * 5\n",
    "\n",
    "# Apply the rounding function using numpy vectorization\n",
    "rounded_results = round_down_to_nearest_5(results)\n",
    "\n",
    "# Use numpy's unique function to get unique rows\n",
    "unique_results = np.unique(rounded_results, axis=0)\n",
    "\n",
    "# Print the results\n",
    "print(unique_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique slices along axis=0:\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n",
      "Unique slices along axis=1:\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n",
      "Unique slices along axis=2:\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example 3D array\n",
    "array_3d = np.array([\n",
    "    [[1, 2, 3], [4, 5, 6]],\n",
    "    [[1, 2, 3], [4, 5, 6]],\n",
    "    [[7, 8, 9], [10, 11, 12]],\n",
    "])\n",
    "\n",
    "# Find unique 2D slices along the first axis (axis=0)\n",
    "unique_slices_axis0 = np.unique(array_3d, axis=0)\n",
    "\n",
    "# Find unique 2D slices along the second axis (axis=1)\n",
    "unique_slices_axis1 = np.unique(array_3d, axis=1)\n",
    "\n",
    "# Find unique 1D slices along the third axis (axis=2)\n",
    "unique_slices_axis2 = np.unique(array_3d, axis=2)\n",
    "\n",
    "print(\"Unique slices along axis=0:\")\n",
    "print(unique_slices_axis0)\n",
    "\n",
    "print(\"Unique slices along axis=1:\")\n",
    "print(unique_slices_axis1)\n",
    "\n",
    "print(\"Unique slices along axis=2:\")\n",
    "print(unique_slices_axis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lance DB testing\n",
    "https://github.com/lancedb/lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lancedb in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (0.6.13)\n",
      "Requirement already satisfied: deprecation in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (2.1.0)\n",
      "Requirement already satisfied: pylance==0.10.12 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (0.10.12)\n",
      "Requirement already satisfied: ratelimiter~=1.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (1.2.0.post0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (2.31.0)\n",
      "Requirement already satisfied: retry>=0.9.2 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (0.9.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (4.66.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (2.7.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (23.2.0)\n",
      "Requirement already satisfied: semver in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (3.0.2)\n",
      "Requirement already satisfied: cachetools in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (5.3.3)\n",
      "Requirement already satisfied: overrides>=0.7 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from lancedb) (7.7.0)\n",
      "Requirement already satisfied: pyarrow<15.0.1,>=12 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from pylance==0.10.12->lancedb) (15.0.0)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from pylance==0.10.12->lancedb) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from pydantic>=1.10->lancedb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from pydantic>=1.10->lancedb) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from pydantic>=1.10->lancedb) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from requests>=2.31.0->lancedb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from requests>=2.31.0->lancedb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from requests>=2.31.0->lancedb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from requests>=2.31.0->lancedb) (2024.2.2)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from retry>=0.9.2->lancedb) (5.1.1)\n",
      "Requirement already satisfied: py<2.0.0,>=1.4.26 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from retry>=0.9.2->lancedb) (1.11.0)\n",
      "Requirement already satisfied: packaging in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from deprecation->lancedb) (24.0)\n",
      "Requirement already satisfied: ipywidgets in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipywidgets) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/tednaleid/.pyenv/versions/3.12.2/envs/d2notebooks-3.12.2/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install lancedb\n",
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>item</th>\n",
       "      <th>price</th>\n",
       "      <th>_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5.9, 26.5]</td>\n",
       "      <td>bar</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14257.059570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3.1, 4.1]</td>\n",
       "      <td>foo</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18586.421875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        vector item  price     _distance\n",
       "0  [5.9, 26.5]  bar   20.0  14257.059570\n",
       "1   [3.1, 4.1]  foo   10.0  18586.421875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "\n",
    "uri = \"data/sample-lancedb\"\n",
    "db = lancedb.connect(uri)\n",
    "table = db.create_table(\"my_table\",\n",
    "                         exist_ok=True,\n",
    "                         data=[{\"vector\": [3.1, 4.1], \"item\": \"foo\", \"price\": 10.0},\n",
    "                               {\"vector\": [5.9, 26.5], \"item\": \"bar\", \"price\": 20.0}])\n",
    "result = table.search([100, 100]).limit(2).to_pandas()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: see what the performance is if we insert all the armor pieces into a lancedb table and then query for the best outfits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2notebooks-3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
